{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca509818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy import signal\n",
    "import IPython.display as ipd\n",
    "\n",
    "def wiener_filter(noisy_signal, sample_rate, noise_estimate=None, frame_length=0.025, frame_step=0.010, alpha=2.0):\n",
    "    \"\"\"\n",
    "    Apply Wiener filter for speech denoising\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    noisy_signal : numpy array\n",
    "        Noisy speech signal\n",
    "    sample_rate : int\n",
    "        Sampling rate of the signal\n",
    "    noise_estimate : numpy array, optional\n",
    "        Estimated noise signal. If None, first 0.5 seconds are assumed to be noise\n",
    "    frame_length : float\n",
    "        Length of each frame in seconds\n",
    "    frame_step : float\n",
    "        Step between frames in seconds\n",
    "    alpha : float\n",
    "        Over-subtraction factor to control noise reduction amount\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    enhanced_signal : numpy array\n",
    "        Denoised speech signal\n",
    "    \"\"\"\n",
    "    # Convert frame length and step from seconds to samples\n",
    "    frame_len = int(frame_length * sample_rate)\n",
    "    frame_step_samples = int(frame_step * sample_rate)\n",
    "    \n",
    "    # If noise estimate not provided, use first 0.5s of signal\n",
    "    if noise_estimate is None:\n",
    "        noise_length = int(0.5 * sample_rate)\n",
    "        noise_estimate = noisy_signal[:noise_length]\n",
    "    \n",
    "    # Calculate noise power spectrum\n",
    "    noise_psd = estimate_spectrum(noise_estimate, frame_len)\n",
    "    \n",
    "    # Prepare for processing in frames\n",
    "    num_frames = 1 + int((len(noisy_signal) - frame_len) / frame_step_samples)\n",
    "    enhanced_signal = np.zeros_like(noisy_signal)\n",
    "    window = np.hamming(frame_len)\n",
    "    \n",
    "    # Process each frame\n",
    "    for i in range(num_frames):\n",
    "        # Extract frame\n",
    "        start = i * frame_step_samples\n",
    "        end = start + frame_len\n",
    "        if end > len(noisy_signal):\n",
    "            break\n",
    "            \n",
    "        frame = noisy_signal[start:end]\n",
    "        \n",
    "        # Apply window\n",
    "        windowed_frame = frame * window\n",
    "        \n",
    "        # FFT\n",
    "        frame_fft = np.fft.rfft(windowed_frame)\n",
    "        frame_power = np.abs(frame_fft) ** 2\n",
    "        \n",
    "        # Wiener filter formula: H(f) = P_s(f) / (P_s(f) + P_n(f))\n",
    "        # Where P_s(f) is estimated as P_y(f) - P_n(f)\n",
    "        snr = frame_power / (noise_psd + 1e-10)\n",
    "        gain = snr / (1 + snr)  # Wiener filter\n",
    "        \n",
    "        # Apply gain to the frame\n",
    "        enhanced_fft = frame_fft * gain\n",
    "        \n",
    "        # Inverse FFT\n",
    "        enhanced_frame = np.fft.irfft(enhanced_fft)\n",
    "        \n",
    "        # Overlap-add\n",
    "        enhanced_signal[start:end] += enhanced_frame * window\n",
    "    \n",
    "    return enhanced_signal\n",
    "\n",
    "def estimate_spectrum(signal_segment, frame_len):\n",
    "    \"\"\"\n",
    "    Estimate the power spectral density of a signal segment\n",
    "    \"\"\"\n",
    "    # Split into frames with 50% overlap\n",
    "    num_frames = int(len(signal_segment) / (frame_len/2)) - 1\n",
    "    window = np.hamming(frame_len)\n",
    "    spectrum = np.zeros(frame_len // 2 + 1)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        start = int(i * frame_len / 2)\n",
    "        frame = signal_segment[start:start+frame_len]\n",
    "        if len(frame) < frame_len:\n",
    "            break\n",
    "        windowed = frame * window\n",
    "        fft = np.fft.rfft(windowed)\n",
    "        spectrum += np.abs(fft) ** 2\n",
    "    \n",
    "    return spectrum / num_frames if num_frames > 0 else spectrum\n",
    "\n",
    "def demo_wiener_filter(clean_path=None, noise_path=None, noisy_path=None, snr_db=5):\n",
    "    \"\"\"\n",
    "    Demonstrate Wiener filter on speech data\n",
    "    \n",
    "    Either provide:\n",
    "    - noisy_path: path to already noisy speech\n",
    "    OR\n",
    "    - clean_path and noise_path: to mix clean speech with noise at specified SNR\n",
    "    \"\"\"\n",
    "    if noisy_path:\n",
    "        # Load noisy speech\n",
    "        sample_rate, noisy_signal = wavfile.read(noisy_path)\n",
    "        if len(noisy_signal.shape) > 1:  # Convert stereo to mono if needed\n",
    "            noisy_signal = noisy_signal.mean(axis=1)\n",
    "    elif clean_path and noise_path:\n",
    "        # Load clean speech and noise\n",
    "        sample_rate, clean_signal = wavfile.read(clean_path)\n",
    "        if len(clean_signal.shape) > 1:\n",
    "            clean_signal = clean_signal.mean(axis=1)\n",
    "            \n",
    "        noise_rate, noise_signal = wavfile.read(noise_path)\n",
    "        if len(noise_signal.shape) > 1:\n",
    "            noise_signal = noise_signal.mean(axis=1)\n",
    "        \n",
    "        # Ensure same sample rate\n",
    "        if noise_rate != sample_rate:\n",
    "            raise ValueError(\"Clean and noise signals must have the same sample rate\")\n",
    "        \n",
    "        # Adjust noise level to desired SNR\n",
    "        clean_power = np.mean(clean_signal**2)\n",
    "        noise_power = np.mean(noise_signal**2)\n",
    "        scaling_factor = np.sqrt(clean_power / (noise_power * (10**(snr_db/10))))\n",
    "        \n",
    "        # Trim or repeat noise to match clean signal length\n",
    "        if len(noise_signal) < len(clean_signal):\n",
    "            noise_signal = np.tile(noise_signal, int(np.ceil(len(clean_signal) / len(noise_signal))))\n",
    "        noise_signal = noise_signal[:len(clean_signal)]\n",
    "        \n",
    "        # Mix signals\n",
    "        scaled_noise = scaling_factor * noise_signal\n",
    "        noisy_signal = clean_signal + scaled_noise\n",
    "    else:\n",
    "        raise ValueError(\"Either provide noisy_path or both clean_path and noise_path\")\n",
    "    \n",
    "    # Apply Wiener filter\n",
    "    enhanced_signal = wiener_filter(noisy_signal, sample_rate)\n",
    "    \n",
    "    # Normalize signals for plotting\n",
    "    if clean_path:\n",
    "        clean_signal = clean_signal / np.max(np.abs(clean_signal))\n",
    "    noisy_signal = noisy_signal / np.max(np.abs(noisy_signal))\n",
    "    enhanced_signal = enhanced_signal / np.max(np.abs(enhanced_signal))\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    if clean_path:\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.title('Clean Speech')\n",
    "        plt.plot(clean_signal)\n",
    "        plt.xlim([0, len(clean_signal)])\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "    else:\n",
    "        plt.subplot(2, 1, 1)\n",
    "    plt.title('Noisy Speech')\n",
    "    plt.plot(noisy_signal)\n",
    "    plt.xlim([0, len(noisy_signal)])\n",
    "    \n",
    "    if clean_path:\n",
    "        plt.subplot(3, 1, 3)\n",
    "    else:\n",
    "        plt.subplot(2, 1, 2)\n",
    "    plt.title('Enhanced Speech')\n",
    "    plt.plot(enhanced_signal)\n",
    "    plt.xlim([0, len(enhanced_signal)])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the signals for audio playback\n",
    "    return {\n",
    "        'noisy': (noisy_signal, sample_rate),\n",
    "        'enhanced': (enhanced_signal, sample_rate),\n",
    "        'clean': (clean_signal, sample_rate) if clean_path else None\n",
    "    }\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# signals = demo_wiener_filter(clean_path='clean_speech.wav', noise_path='noise.wav', snr_db=5)\n",
    "\n",
    "# To listen to the results:\n",
    "# ipd.display(ipd.Audio(signals['noisy'][0], rate=signals['noisy'][1]))\n",
    "# ipd.display(ipd.Audio(signals['enhanced'][0], rate=signals['enhanced'][1]))\n",
    "# if signals['clean']:\n",
    "#     ipd.display(ipd.Audio(signals['clean'][0], rate=signals['clean'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee3ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file columns:\n",
      "['noisy_file', 'clean_file', 'noise_file', 'snr']\n",
      "Small dataset contains 8000 examples\n",
      "Features: {'id': Value(dtype='string', id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n",
      "{'id': Value(dtype='string', id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n",
      "\n",
      "Combined dataset size: 20396 examples\n",
      "Combined dataset features: {'id': Value(dtype='string', id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio, DatasetDict,load_dataset ,concatenate_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = \"/home/hkngae/COMP5412/data/NoisySpeechDataset\"\n",
    "demand_dir = \"/home/hkngae/COMP5412/data/local_datasets\"\n",
    "metadata_file = os.path.join(dataset_dir, \"metadata.csv\")\n",
    "first_n = 8000  # Number of examples to load for trial\n",
    "demand_ds = load_dataset(\"JacobLinCool/VoiceBank-DEMAND-16k\", cache_dir=demand_dir)\n",
    "\n",
    "### Dataset demand_ds contains: ['train', 'test']\n",
    "### Split 'train' contains 11572 examples\n",
    "### Features: {'id': Value(dtype='string', id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n",
    "### Split 'test' contains 824 examples\n",
    "### Features: {'id': Value(dtype='string', id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n",
    "\n",
    "\n",
    "\n",
    "# Check if metadata file exists and read its structure first\n",
    "if os.path.exists(metadata_file):\n",
    "    # Just peek at the first few rows to see the structure\n",
    "    print(\"Metadata file columns:\")\n",
    "    print(pd.read_csv(metadata_file, nrows=1).columns.tolist())\n",
    "\n",
    "    # Load only the first n examples from metadata for trial\n",
    "    metadata_df = pd.read_csv(metadata_file).head(first_n)\n",
    "\n",
    "    # Assuming columns like \"noisy_file\", \"clean_file\", \"snr\" exist\n",
    "    # Adapt these column names to match your actual metadata structure\n",
    "    dataset_dict = {\n",
    "        \"id\": [str(i) for i in range(len(metadata_df))],\n",
    "        \"noisy\": metadata_df[\"noisy_file\"].tolist() if \"noisy_file\" in metadata_df.columns else [],\n",
    "        \"clean\": metadata_df[\"clean_file\"].tolist() if \"clean_file\" in metadata_df.columns else [],\n",
    "        #\"snr\": metadata_df[\"snr\"].tolist() if \"snr\" in metadata_df.columns else []\n",
    "    }\n",
    "    \n",
    "    # Create the dataset\n",
    "    small_ds = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    # Add audio loading functionality \n",
    "    if \"noisy_file\" in metadata_df.columns:\n",
    "        small_ds = small_ds.cast_column(\"noisy\", Audio(sampling_rate=16000))\n",
    "    if \"clean_file\" in metadata_df.columns:\n",
    "        small_ds = small_ds.cast_column(\"clean\", Audio(sampling_rate=16000))\n",
    "    \n",
    "    # Inspect the small dataset\n",
    "    print(f\"Small dataset contains {len(small_ds)} examples\")\n",
    "    print(f\"Features: {small_ds.features}\")\n",
    "    print(demand_ds[\"train\"].features)\n",
    "    #concat with demand_ds['train']\n",
    "    combined_ds = DatasetDict({\n",
    "        'custom': small_ds,\n",
    "        'train': demand_ds['train'],\n",
    "        'test': demand_ds['test']\n",
    "        })\n",
    "    full_ds = concatenate_datasets([combined_ds['train'], combined_ds['test'], combined_ds['custom']])\n",
    "\n",
    "    print(f\"\\nCombined dataset size: {len(full_ds)} examples\")\n",
    "    print(f\"Combined dataset features: {full_ds.features}\")\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(f\"Metadata file not found at {metadata_file}\")\n",
    "    print(\"Please check the path or create the metadata file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84dc29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pesq import calculate_pesq\n",
    "from utils.stoi import calculate_stoi\n",
    "from utils.snr import calculate_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c1a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'clean', 'noisy'],\n",
      "    num_rows: 4080\n",
      "})\n",
      "{'id': Value(dtype='string', id=None), 'clean': Audio(sampling_rate=16000, mono=True, decode=True, id=None), 'noisy': Audio(sampling_rate=16000, mono=True, decode=True, id=None)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m snr_before = calculate_snr(example[\u001b[33m'\u001b[39m\u001b[33mclean\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m], noisy_signal-example[\u001b[33m'\u001b[39m\u001b[33mclean\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m])    \n\u001b[32m     27\u001b[39m stoi_before = calculate_stoi(example[\u001b[33m'\u001b[39m\u001b[33mclean\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m], noisy_signal)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m pesq_before = \u001b[43mcalculate_pesq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#display(Audio(noisy_signal, rate=sample_rate))\u001b[39;00m\n\u001b[32m     34\u001b[39m enhanced_signal = wiener_filter(noisy_signal, sample_rate, noise_estimate=\u001b[38;5;28;01mNone\u001b[39;00m, frame_length=\u001b[32m0.025\u001b[39m, frame_step=\u001b[32m0.012\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/COMP5412/utils/pesq.py:33\u001b[39m, in \u001b[36mcalculate_pesq\u001b[39m\u001b[34m(reference_array, degraded_array, fs, mode)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Calculate PESQ score\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     score = \u001b[43mpesq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegraded_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/COMP5412/lib/python3.11/site-packages/pesq/_pesq.py:114\u001b[39m, in \u001b[36mpesq\u001b[39m\u001b[34m(fs, ref, deg, mode, on_error)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    ref: numpy 1D array, reference audio signal\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m \u001b[33;03m    pesq_score: float, P.862.2 Prediction (MOS-LQO)\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    113\u001b[39m _check_fs_mode(mode, fs, USAGE)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pesq_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/COMP5412/lib/python3.11/site-packages/pesq/_pesq.py:65\u001b[39m, in \u001b[36m_pesq_inner\u001b[39m\u001b[34m(ref, deg, fs, mode, on_error)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error == PesqError.RETURN_VALUES:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cypesq_retvals(\n\u001b[32m     60\u001b[39m         fs,\n\u001b[32m     61\u001b[39m         (ref / max_val).astype(np.float32),\n\u001b[32m     62\u001b[39m         (deg / max_val).astype(np.float32),\n\u001b[32m     63\u001b[39m         mode_code\n\u001b[32m     64\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcypesq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode_code\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio, display\n",
    "# get 5 examples from the dataset\n",
    "train_ds,test_ds = full_ds.train_test_split(test_size=0.2).values()\n",
    "sample_ds = test_ds\n",
    "\n",
    "print(sample_ds)\n",
    "\n",
    "print(sample_ds.features)\n",
    "\n",
    "SNR_before = []\n",
    "SNR_after = []\n",
    "PESQ_before = []\n",
    "PESQ_after = []\n",
    "STOI_before = []\n",
    "STOI_after = []\n",
    "\n",
    "\n",
    "for i, example in enumerate(sample_ds):\n",
    "\n",
    "    noisy_signal = np.array(example['noisy'][\"array\"])\n",
    "    noisy_signal = noisy_signal[:64000]  # Truncate to 1 second\n",
    "    clean_signal = np.array(example['clean'][\"array\"])\n",
    "    clean_signal = clean_signal[:64000]  # Truncate to 1 second\n",
    "    sample_rate = 16000\n",
    "\n",
    "\n",
    "    #calculate snr, stoi and pesq\n",
    "    snr_before = calculate_snr(clean_signal, noisy_signal-clean_signal)    \n",
    "\n",
    "    stoi_before = calculate_stoi(clean_signal, noisy_signal)\n",
    "\n",
    "    pesq_before = calculate_pesq(clean_signal, noisy_signal, sample_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "    #display(Audio(noisy_signal, rate=sample_rate))\n",
    "    enhanced_signal = wiener_filter(noisy_signal, sample_rate, noise_estimate=None, frame_length=0.025, frame_step=0.012)\n",
    "    \n",
    "\n",
    "    snr_after = calculate_snr(clean_signal, enhanced_signal-clean_signal)\n",
    "\n",
    "    stoi_after = calculate_stoi(clean_signal, enhanced_signal)\n",
    "\n",
    "    pesq_after = calculate_pesq(clean_signal, enhanced_signal, sample_rate)\n",
    "\n",
    "    #display(Audio(enhanced_signal, rate=sample_rate))\n",
    "    SNR_before.append(snr_before)\n",
    "    SNR_after.append(snr_after)\n",
    "    PESQ_before.append(pesq_before)\n",
    "    PESQ_after.append(pesq_after)\n",
    "    STOI_before.append(stoi_before)\n",
    "    STOI_after.append(stoi_after)\n",
    "\n",
    "print(\"Avg SNR before: \", np.mean(SNR_before))\n",
    "print(\"Avg SNR after: \", np.mean(SNR_after))\n",
    "print(\"Avg SNR improvement: \", np.mean(SNR_after) - np.mean(SNR_before))\n",
    "print(\"Avg PESQ before: \", np.mean(PESQ_before))\n",
    "print(\"Avg PESQ after: \", np.mean(PESQ_after))\n",
    "print(\"Avg PESQ improvement: \", np.mean(PESQ_after) - np.mean(PESQ_before))\n",
    "print(\"Avg STOI before: \", np.mean(STOI_before))\n",
    "print(\"Avg STOI after: \", np.mean(STOI_after))\n",
    "print(\"Avg STOI improvement: \", np.mean(STOI_after) - np.mean(STOI_before))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecf744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP5412",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
